import discord
import os
import tempfile
import asyncio
from discord.ext import commands
from app.services.moderation_service import ModerationService
from app.services.audio_service import AudioService
from app.services.meeting_service import MeetingService
from PIL import Image
import io
from pydub import AudioSegment
import numpy as np
import torch
from datetime import datetime

# Load services
moderation_service = ModerationService()
audio_service = AudioService()
meeting_service = MeetingService()

TOKEN = "MTM0NzE5NTM5MDM4NjI0NTcwMw.GQkCVO.FPr2ALTRFGjaD7szokYb0teTqNnxZdNJL4p4L0"

intents = discord.Intents.default()
intents.message_content = True
intents.voice_states = True

bot = commands.Bot(command_prefix="!", intents=intents)


# -------------------------------
# AUTOMATIC CONTENT MODERATION
# -------------------------------
@bot.event
async def on_ready():
    print(f"{bot.user} is online!")


@bot.event
async def on_message(message):
    if message.author == bot.user:
        return

    is_inappropriate = False

    if message.attachments:
        for attachment in message.attachments:
            try:
                content_type = attachment.content_type
                if content_type.startswith("image/"):
                    image_bytes = await attachment.read()
                    image = Image.open(io.BytesIO(image_bytes))
                    result = moderation_service.analyze_image(image)
                    is_inappropriate = result.get("is_inappropriate", False)
                    analysis_type = "Image"
                elif content_type.startswith("audio/"):
                    audio_bytes = await attachment.read()
                    result = moderation_service.analyze_audio(audio_bytes)
                    is_inappropriate = result.get("is_inappropriate", False)
                    analysis_type = "Audio"
                elif content_type.startswith("video/"):
                    video_bytes = await attachment.read()
                    result = moderation_service.analyze_video(video_bytes)
                    is_inappropriate = result.get("is_inappropriate", False)
                    analysis_type = "Video"
                else:
                    analysis_type = "Attachment (Unsupported Type)"
                    print(f"Unsupported attachment type: {content_type}")

                if is_inappropriate:
                    print(
                        f"Inappropriate {analysis_type} detected from {message.author.name} in {message.channel.name}, deleting message."
                    )
                    break

            except Exception as e:
                print(f"Error analyzing {analysis_type} attachment: {e}")
                is_inappropriate = False

    else:
        text_result = moderation_service.analyze_text(message.content)
        is_inappropriate = text_result.get("is_inappropriate", False)
        analysis_type = "Text"

    if is_inappropriate:
        await message.delete()
        warning_message = f"‚ö†Ô∏è Your message in {message.channel.name} was removed due to inappropriate content ({analysis_type} analysis)."
        try:
            await message.author.send(warning_message)
        except discord.errors.Forbidden:
            print(f"Could not send DM warning to {message.author.name}")
        print(
            f"Deleted {analysis_type} message from {message.author.name}: {message.content if analysis_type == 'Text' else '<attachment(s)>'}"
        )

    await bot.process_commands(message)


# Helper function to create markdown file
def create_mom_markdown(mom, channel_name):
    now = datetime.now()
    date_str = now.strftime("%B %d, %Y")
    time_str = now.strftime("%I:%M %p")

    markdown_content = f"""# Meeting Minutes

## Meeting Details
- **Date:** {date_str}
- **Time:** {time_str}
- **Channel:** {channel_name}

## Summary
{mom}

---
*Generated by MoM Bot*
"""
    return markdown_content


# -------------------------------
# MOM GENERATION (VOICE RECORDING)
# -------------------------------
@bot.command()
async def join(ctx):
    """Joins voice channel and starts recording"""
    if not ctx.author.voice:
        await ctx.send("‚ùå You must be in a voice channel!")
        return

    channel = ctx.author.voice.channel
    print(f"Attempting to join voice channel: {channel.name}")

    try:
        vc = await channel.connect()
        print(f"Successfully connected to voice channel: {channel.name}")
    except discord.ClientException:
        await ctx.send("‚ùå Already connected to a voice channel!")
        return

    sink = discord.sinks.WaveSink()
    print(f"Created WaveSink for recording")

    # Start recording
    vc.start_recording(
        sink,
        finished_callback,  # Direct coroutine reference
        ctx.channel,  # Pass the channel as an argument
    )
    print(f"Recording started in channel: {channel.name}")

    await ctx.send(f"üéôÔ∏è Recording started in **{channel.name}**!")


@bot.command()
async def leave(ctx):
    """Stops recording and generates MoM"""
    vc = ctx.voice_client

    if not vc:
        await ctx.send("‚ùå Not recording in any channel!")
        return

    print(f"Stopping recording in channel: {vc.channel.name}")
    vc.stop_recording()
    await vc.disconnect()
    await ctx.send("‚è≥ Stopped recording. Processing meeting minutes...")


async def finished_callback(sink, channel):
    """Process recorded audio and generate meeting minutes"""
    try:
        # 1. Check if we have any audio data
        if not sink.audio_data:
            await channel.send("‚ùå No audio recorded")
            return

        # 2. Create a temporary directory to work with files
        with tempfile.TemporaryDirectory() as temp_dir:
            print(f"Created temporary directory: {temp_dir}")

            # Process each user's audio
            user_count = 0
            audio_files = []

            for user_id, audio_data in sink.audio_data.items():
                user_count += 1
                # Get user info for logging
                try:
                    user = await bot.fetch_user(int(user_id))
                    user_name = user.name if user else f"User_{user_id}"
                except:
                    user_name = f"User_{user_id}"

                # Reset the file pointer to the beginning
                audio_data.file.seek(0)

                # Write user's audio to a temporary file
                user_audio_path = os.path.join(temp_dir, f"user_{user_id}.wav")
                with open(user_audio_path, "wb") as f:
                    f.write(audio_data.file.read())

                file_size = os.path.getsize(user_audio_path)
                print(f"Saved audio from {user_name}, file size: {file_size} bytes")

                if file_size > 1000:  # Only include files with actual content
                    audio_files.append(user_audio_path)

            if user_count == 0 or len(audio_files) == 0:
                await channel.send("‚ùå No valid audio recorded")
                return

            print(f"Processing audio from {len(audio_files)} users")

            # 3. Merge audio streams using your service's method
            try:
                # Get raw audio bytes from all files
                combined_audio_bytes = audio_service.merge_audio_streams(audio_files)
                print(
                    f"Successfully merged {len(audio_files)} audio streams, size: {len(combined_audio_bytes)} bytes"
                )

                if len(combined_audio_bytes) < 1000:
                    await channel.send("‚ùå Combined audio is too small to process")
                    return

                # 4. Transcribe the combined audio using your service
                await channel.send("üîç Transcribing audio...")
                transcription_segments = audio_service.transcribe_audio(
                    combined_audio_bytes
                )

                if not transcription_segments:
                    await channel.send(
                        "‚ùå Could not transcribe the audio. Please check if there was clear speech in the recording."
                    )
                    return

                # 5. Combine all segments into a single transcript
                transcript = " ".join(
                    [segment.get("text", "") for segment in transcription_segments]
                )
                print(f"Transcription complete: {len(transcript)} characters")

                if not transcript:
                    await channel.send("‚ùå Transcription resulted in empty text")
                    return

                # 6. Generate summary from transcript
                await channel.send("üìù Generating meeting minutes...")
                summary = meeting_service.generate_summary(transcript)
                mom = summary.get("summary", "No summary available.")

                # 7. Create a markdown file instead of sending directly to channel
                if mom and mom != "No summary available.":
                    # Generate markdown content
                    markdown_content = create_mom_markdown(mom, channel.name)

                    # Create a temporary markdown file
                    md_file_path = os.path.join(temp_dir, "meeting_minutes.md")
                    with open(md_file_path, "w", encoding="utf-8") as f:
                        f.write(markdown_content)

                    # Send the file to the channel
                    await channel.send(
                        "üìù **Meeting Minutes:**",
                        file=discord.File(md_file_path, "meeting_minutes.md"),
                    )
                else:
                    await channel.send(
                        "‚ùå Could not generate meeting minutes from the transcript."
                    )
                    # Create a simple transcript file as fallback
                    transcript_file_path = os.path.join(temp_dir, "transcript.md")
                    with open(transcript_file_path, "w", encoding="utf-8") as f:
                        f.write(f"# Meeting Transcript\n\n{transcript}")

                    await channel.send(
                        "üìù **Transcript:**",
                        file=discord.File(transcript_file_path, "transcript.md"),
                    )

            except Exception as e:
                await channel.send(f"‚ùå Audio processing error: {str(e)}")
                print(f"Error processing audio: {e}")
                import traceback

                traceback.print_exc()

    except Exception as e:
        await channel.send(f"‚ùå Critical error: {str(e)}")
        print(f"Critical error: {e}")
        import traceback

        traceback.print_exc()


# -------------------------------
# MOM GENERATION FROM AUDIO FILE UPLOAD
# -------------------------------
@bot.command()
async def mom_from_file(ctx):
    """Generates MoM from an uploaded audio file."""
    if not ctx.message.attachments:
        await ctx.send("‚ùå Please attach an audio file to the command!")
        return

    attachment = ctx.message.attachments[0]
    if not attachment.filename.lower().endswith((".wav", ".mp3", ".m4a", ".ogg")):
        await ctx.send(
            "‚ùå Invalid file type. Please upload an audio file (.wav, .mp3, .m4a, or .ogg)."
        )
        return

    await ctx.send("‚è≥ Processing audio file, generating meeting minutes...")

    try:
        # 1. Download the audio file as bytes
        audio_bytes = await attachment.read()
        print(
            f"Downloaded audio file: {attachment.filename}, size: {len(audio_bytes)} bytes"
        )

        if len(audio_bytes) < 1000:
            await ctx.send("‚ùå Audio file is too small to process")
            return

        # 2. Convert to correct format if needed
        with tempfile.TemporaryDirectory() as temp_dir:
            # Save the original file
            temp_input_path = os.path.join(temp_dir, attachment.filename)
            with open(temp_input_path, "wb") as f:
                f.write(audio_bytes)

            # Convert to the correct format using pydub
            audio = AudioSegment.from_file(temp_input_path)

            # Add silent padding at beginning and end
            silence = AudioSegment.silent(duration=500)  # 500ms silence
            audio = silence + audio + silence

            # Convert to 16kHz mono
            audio = audio.set_frame_rate(16000).set_channels(1)

            # Export as bytes
            temp_output = io.BytesIO()
            audio.export(temp_output, format="wav")
            processed_audio_bytes = temp_output.getvalue()

            print(f"Processed audio, new size: {len(processed_audio_bytes)} bytes")

            # 3. Transcribe the processed audio
            await ctx.send("üîç Transcribing audio...")
            transcription_segments = audio_service.transcribe_audio(
                processed_audio_bytes
            )

            if not transcription_segments:
                await ctx.send(
                    "‚ùå Could not transcribe the audio. Please check if the file contains clear speech."
                )
                return

            # 4. Combine all segments into a single transcript
            transcript = " ".join(
                [segment.get("text", "") for segment in transcription_segments]
            )
            print(f"Transcription complete: {len(transcript)} characters")

            if not transcript:
                await ctx.send("‚ùå Transcription resulted in empty text")
                return

            # 5. Generate summary
            await ctx.send("üìù Generating meeting minutes...")
            summary = meeting_service.generate_summary(transcript)
            mom = summary.get("summary", "No summary available.")

            # 6. Create and send a markdown file instead of sending directly to chat
            if mom and mom != "No summary available.":
                # Generate markdown content
                markdown_content = create_mom_markdown(mom, ctx.channel.name)

                # Create a temporary markdown file
                md_file_path = os.path.join(temp_dir, "meeting_minutes.md")
                with open(md_file_path, "w", encoding="utf-8") as f:
                    f.write(markdown_content)

                # Send the file to the channel
                await ctx.send(
                    "üìù **Meeting Minutes from Uploaded File:**",
                    file=discord.File(md_file_path, "meeting_minutes.md"),
                )
            else:
                await ctx.send(
                    "‚ùå Could not generate meeting minutes from the transcript."
                )
                # Create a simple transcript file as fallback
                transcript_file_path = os.path.join(temp_dir, "transcript.md")
                with open(transcript_file_path, "w", encoding="utf-8") as f:
                    f.write(f"# Meeting Transcript\n\n{transcript}")

                await ctx.send(
                    "üìù **Transcript:**",
                    file=discord.File(transcript_file_path, "transcript.md"),
                )

    except Exception as e:
        await ctx.send(f"‚ùå Error processing uploaded audio file: {str(e)}")
        print(f"Error processing uploaded audio file: {e}")
        import traceback

        traceback.print_exc()


# -------------------------------
# RUN BOT
# -------------------------------
bot.run(TOKEN)
